{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Data Science in Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book [Mining the Social Web](http://www.webpages.uidaho.edu/~stevel/504/Mining-the-Social-Web-2nd-Edition.pdf) \n",
    "* The codes for [Chapter 1](http://bit.ly/1qCtMrr) and [Chapter 9](http://bit.ly/1u7eP33)\n",
    "* [TED Talks](https://www.ted.com/talks) for examples of 10 minutes talks.\n",
    "\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in Jupyter Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: pick a data science problem that you plan to solve using Twitter Data\n",
    "* The problem should be important and interesting, which has a potential impact in some area.\n",
    "* The problem should be solvable using twitter data and data science solutions.\n",
    "\n",
    "Please briefly describe in the following cell: what problem are you trying to solve? why this problem is important and interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi worldy\n"
     ]
    }
   ],
   "source": [
    "print \"hi worldy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection: Download Twitter Data using API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In order to solve the above problem, you need to collect some twitter data. You could select a topic that is relevant to your problem, and use Twitter API to download the relevant tweets. It is recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "# Define a Function to Login Twitter API\n",
    "def oauth_login():\n",
    "    # Go to http://twitter.com/apps/new to create an app and get values\n",
    "    # for these credentials that you'll need to provide in place of these\n",
    "    # empty string values that are defined as placeholders.\n",
    "    # See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "    # on Twitter's OAuth implementation.\n",
    "    \n",
    "    CONSUMER_KEY = 'ouMDjeSY1kY9hqUDuN3WYGxEJ'\n",
    "    CONSUMER_SECRET ='Gzw5aljoe0cONRhof5mQ0bbSvqpUjyzUiGDBe5Lfoskzki7xUe'\n",
    "    OAUTH_TOKEN = '958500278151602176-jTycQLTNHoR3CEUYz5rJOUg6w7VSB7M'\n",
    "    OAUTH_TOKEN_SECRET = '7quNIFQRGI29WZ1ba3UXDSNGQwuQf8MQo8JRVEwdhU8lI'\n",
    "    \n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                               CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from urllib2 import URLError\n",
    "from httplib import BadStatusLine\n",
    "import json\n",
    "import twitter\n",
    "\n",
    "def make_twitter_request(twitter_api_func, max_errors=10, *args, **kw): \n",
    "    # A nested helper function that handles common HTTPErrors. Return an updated\n",
    "    # value for wait_period if the problem is a 500 level error. Block until the\n",
    "    # rate limit is reset if it's a rate limiting issue (429 error). Returns None\n",
    "    # for 401 and 404 errors, which requires special handling by the caller.\n",
    "    def handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
    "    \n",
    "        if wait_period > 3600: # Seconds\n",
    "            print >> sys.stderr, 'Too many retries. Quitting.'\n",
    "            raise e\n",
    "    \n",
    "        # See https://dev.twitter.com/docs/error-codes-responses for common codes\n",
    "    \n",
    "        if e.e.code == 401:\n",
    "            print >> sys.stderr, 'Encountered 401 Error (Not Authorized)'\n",
    "            return None\n",
    "        elif e.e.code == 404:\n",
    "            print >> sys.stderr, 'Encountered 404 Error (Not Found)'\n",
    "            return None\n",
    "        elif e.e.code == 429: \n",
    "            print >> sys.stderr, 'Encountered 429 Error (Rate Limit Exceeded)'\n",
    "            if sleep_when_rate_limited:\n",
    "                print >> sys.stderr, \"Retrying in 15 minutes...ZzZ...\"\n",
    "                sys.stderr.flush()\n",
    "                time.sleep(60*15 + 5)\n",
    "                print >> sys.stderr, '...ZzZ...Awake now and trying again.'\n",
    "                return 2\n",
    "            else:\n",
    "                raise e # Caller must handle the rate limiting issue\n",
    "        elif e.e.code in (500, 502, 503, 504):\n",
    "            print >> sys.stderr, 'Encountered %i Error. Retrying in %i seconds' % \\\n",
    "                (e.e.code, wait_period)\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            return wait_period\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # End of nested helper function\n",
    "    \n",
    "    wait_period = 2 \n",
    "    error_count = 0 \n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return twitter_api_func(*args, **kw)\n",
    "        except twitter.api.TwitterHTTPError, e:\n",
    "            error_count = 0 \n",
    "            wait_period = handle_twitter_http_error(e, wait_period)\n",
    "            if wait_period is None:\n",
    "                return\n",
    "        except URLError, e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            print >> sys.stderr, \"URLError encountered. Continuing.\"\n",
    "            if error_count > max_errors:\n",
    "                print >> sys.stderr, \"Too many consecutive errors...bailing out.\"\n",
    "                raise\n",
    "        except BadStatusLine, e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            print >> sys.stderr, \"BadStatusLine encountered. Continuing.\"\n",
    "            if error_count > max_errors:\n",
    "                print >> sys.stderr, \"Too many consecutive errors...bailing out.\"\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harvest_user_timeline(twitter_api, screen_name=None, user_id=None, max_results=1000):\n",
    "    assert (screen_name != None) != (user_id != None), \\\n",
    "    \"Must have screen_name or user_id, but not both\"    \n",
    "    \n",
    "    kw = {  # Keyword args for the Twitter API call\n",
    "        'count': 200,\n",
    "        'trim_user': 'true',\n",
    "        'include_rts' : 'true',\n",
    "        'since_id' : 1\n",
    "        }\n",
    "    \n",
    "    if screen_name:\n",
    "        kw['screen_name'] = screen_name\n",
    "    else:\n",
    "        kw['user_id'] = user_id\n",
    "        \n",
    "    max_pages = 16\n",
    "    results = []\n",
    "    \n",
    "    tweets = make_twitter_request(twitter_api.statuses.user_timeline, **kw)\n",
    "    \n",
    "    if tweets is None: # 401 (Not Authorized) - Need to bail out on loop entry\n",
    "        tweets = []\n",
    "        \n",
    "    results += tweets\n",
    "    \n",
    "    print >> sys.stderr, 'Fetched %i tweets' % len(tweets)\n",
    "    \n",
    "    page_num = 1\n",
    "    \n",
    "    # Many Twitter accounts have fewer than 200 tweets so you don't want to enter\n",
    "    # the loop and waste a precious request if max_results = 200.\n",
    "    \n",
    "    # Note: Analogous optimizations could be applied inside the loop to try and \n",
    "    # save requests. e.g. Don't make a third request if you have 287 tweets out of \n",
    "    # a possible 400 tweets after your second request. Twitter does do some \n",
    "    # post-filtering on censored and deleted tweets out of batches of 'count', though,\n",
    "    # so you can't strictly check for the number of results being 200. You might get\n",
    "    # back 198, for example, and still have many more tweets to go. If you have the\n",
    "    # total number of tweets for an account (by GET /users/lookup/), then you could \n",
    "    # simply use this value as a guide.\n",
    "    \n",
    "    if max_results == kw['count']:\n",
    "        page_num = max_pages # Prevent loop entry\n",
    "    \n",
    "    while page_num < max_pages and len(tweets) > 0 and len(results) < max_results:\n",
    "    \n",
    "        # Necessary for traversing the timeline in Twitter's v1.1 API:\n",
    "        # get the next query's max-id parameter to pass in.\n",
    "        # See https://dev.twitter.com/docs/working-with-timelines.\n",
    "        kw['max_id'] = min([ tweet['id'] for tweet in tweets]) - 1 \n",
    "    \n",
    "        tweets = make_twitter_request(twitter_api.statuses.user_timeline, **kw)\n",
    "        results += tweets\n",
    "\n",
    "        print >> sys.stderr, 'Fetched %i tweets' % (len(tweets),)\n",
    "    \n",
    "        page_num += 1\n",
    "        \n",
    "    print >> sys.stderr, 'Done fetching tweets'\n",
    "\n",
    "    return results[:max_results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetched 200 tweets\n",
      "Fetched 200 tweets\n",
      "Fetched 197 tweets\n",
      "Fetched 200 tweets\n",
      "Fetched 199 tweets\n",
      "Fetched 200 tweets\n",
      "Done fetching tweets\n"
     ]
    }
   ],
   "source": [
    "# Sample usage\n",
    "twitter_api = oauth_login()\n",
    "tweets = harvest_user_timeline(twitter_api, screen_name=\"realDonaldTrump\", \\\n",
    "                               max_results=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~GunnarHorve/47.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_text = [tweet['text'] for tweet in tweets ]\n",
    "words = [w.lower() for t in tweets_text for w in t.split()]\n",
    "\n",
    "from collections import Counter\n",
    "c = Counter(words)\n",
    "useless = ['the','to','of','and','a','in','for','is','our','are','on','that','i','with','was','it','we','my','be','has','you','as','at']\n",
    "frequency = c.most_common()[:(50+len(useless))]\n",
    "w = [tuple[0] for tuple in frequency if tuple[0] not in useless]\n",
    "f = [tuple[1] for tuple in frequency if tuple[0] not in useless]\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly\n",
    "\n",
    "plotly.tools.set_credentials_file(username='GunnarHorve', api_key='yLpWaU0bvuFHjFMsepgw')\n",
    "data = [Bar(x=w,y=f)]\n",
    "py.iplot(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report  statistics about the tweets you collected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total number of tweets collected:  < INSERT THE NUMBER HERE>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration: Exploring the Tweets and Tweet Entities\n",
    "\n",
    "**(1) Word Count:** \n",
    "* Load the tweets you collected in the local file (txt or json)\n",
    "* compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 most-frequent words with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (2) Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 most-retweeted tweets in your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot the top 10 most-frequent hashtags and top 10 most-mentioned users in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of the number of user mentions in the list using the following bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[0, 10, 20, 30, 40, 50, 100]\n",
    "\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " ** (4) Getting \"All\" friends and \"All\" followers of a popular user in the tweets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers in your collection of tweets.\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Solution: implement a data science solution to the problem you are trying to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly describe the idea of your solution to the problem in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write codes to implement the solution in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results: summarize and visualize the results discovered from the analysis\n",
    "\n",
    "Please use figures, tables, or videos to communicate the results with the audience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this Jupyter notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"jupyter notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . Each team present their case studies in class for 10 minutes.\n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Please submit through Canvas, in the Assignment \"Case Study 1\".\n",
    "        \n",
    "** Note: Each team only needs to submit one submission in Canvas **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Peer-Review Grading Template:\n",
    "\n",
    "** Total Points: (100 points) ** Please don't worry about the absolute scores, we will rescale the final grading according to the performance of all teams in the class.\n",
    "\n",
    "Please add an \"**X**\" mark in front of your rating: \n",
    "\n",
    "For example:\n",
    "\n",
    "*2: bad*\n",
    "          \n",
    "**X** *3: good*\n",
    "    \n",
    "*4: perfect*\n",
    "\n",
    "\n",
    "    ---------------------------------\n",
    "    The Problem: \n",
    "    ---------------------------------\n",
    "    \n",
    "    1. (5 points) how well did the team describe the problem they are trying to solve using twitter data? \n",
    "       0: not clear\n",
    "       1: I can barely understand the problem\n",
    "       2: okay, can be improved\n",
    "       3: good, but can be improved\n",
    "       4: very good\n",
    "       5: crystal clear\n",
    "    \n",
    "    2. (10 points) do you think the problem is important or has a potential impact?\n",
    "        0: not important at all\n",
    "        2: not sure if it is important\n",
    "        4: seems important, but not clear\n",
    "        6: interesting problem\n",
    "        8: an important problem, which I want to know the answer myself\n",
    "       10: very important, I would be happy invest money on a project like this.\n",
    "    \n",
    "    ----------------------------------\n",
    "    Data Collection:\n",
    "    ----------------------------------\n",
    "    \n",
    "    3. (10 points) Do you think the data collected are relevant and sufficient for solving the above problem? \n",
    "       0: not clear\n",
    "       2: I can barely understand what data they are trying to collect\n",
    "       4: I can barely understand why the data is relevant to the problem\n",
    "       6: the data are relevant to the problem, but better data can be collected\n",
    "       8: the data collected are relevant and at a proper scale (> 300 tweets)\n",
    "      10: the data are properly collected and they are sufficient\n",
    "\n",
    "    -----------------------------------\n",
    "    Data Exploration:\n",
    "    -----------------------------------\n",
    "    4. How well did the team solve the following task:\n",
    "    (1) Word Count (5 points):\n",
    "       0: missing answer\n",
    "       1: okay, but with major problems\n",
    "       3: good, but with minor problems\n",
    "       5: perfect\n",
    "    \n",
    "    (2) Find the most popular tweets in your collection of tweets: (5 points)\n",
    "       0: missing answer\n",
    "       1: okay, but with major problems\n",
    "       3: good, but with minor problems\n",
    "       5: perfect\n",
    "    \n",
    "    (3) Find popular twitter entities  (5 points)\n",
    "       0: missing answer\n",
    "       1: okay, but with major problems\n",
    "       3: good, but with minor problems\n",
    "       5: perfect\n",
    "\n",
    "    (4) Find user's followers and friends (5 points)\n",
    "       0: missing answer\n",
    "       1: okay, but with major problems\n",
    "       3: good, but with minor problems\n",
    "       5: perfect\n",
    "\n",
    "    -----------------------------------\n",
    "    The Solution\n",
    "    -----------------------------------\n",
    "    5.  how well did the team describe the solution they used to solve the problem? \n",
    "       0: not clear\n",
    "       2: I can barely understand\n",
    "       4: okay, can be improved\n",
    "       6: good, but can be improved\n",
    "       8: very good\n",
    "       10: crystal clear\n",
    "       \n",
    "    6. how well is the solution in solving the problem? \n",
    "       0: not relevant\n",
    "       1: barely relevant to the problem\n",
    "       2: okay solution, but there is an easier solution.\n",
    "       3: good, but can be improved\n",
    "       4: very good, but solution is simple/old\n",
    "       5: innovative and technically sound\n",
    "       \n",
    "    7. how well did the team implement the solution in python? \n",
    "       0: the code is not relevant to the solution proposed\n",
    "       2: the code is barely understandable, but not relevant\n",
    "       4: okay, the code is clear but incorrect\n",
    "       6: good, the code is correct, but with major errors\n",
    "       8: very good, the code is correct, but with minor errors\n",
    "      10: perfect \n",
    "   \n",
    "    -----------------------------------\n",
    "    The Results\n",
    "    -----------------------------------\n",
    "     8.  How well did the team present the results they found in the data? \n",
    "       0: not clear\n",
    "       2: I can barely understand\n",
    "       4: okay, can be improved\n",
    "       6: good, but can be improved\n",
    "       8: very good\n",
    "      10: crystal clear\n",
    "       \n",
    "     9.  How do you think the results they found in the data? \n",
    "       0: not clear\n",
    "       1: likely to be wrong\n",
    "       2: okay, maybe wrong\n",
    "       3: good, but can be improved\n",
    "       4: make sense, but not interesting\n",
    "       5: make sense and very interesting\n",
    "     \n",
    "    -----------------------------------\n",
    "    The Presentation\n",
    "    -----------------------------------\n",
    "    10. How all the different parts (data, problem, solution, result) fit together as a coherent story?  \n",
    "       0: they are irrelevant\n",
    "       1: I can barely understand how they are related to each other\n",
    "       2: okay, the problem is good, but the solution doesn't match well, or the problem is not solvable.\n",
    "       3: good, but the results don't make much sense in the context\n",
    "       4: very good fit, but not exciting (the storyline can be improved/polished)\n",
    "       5: a perfect story\n",
    "      \n",
    "    11. Did the presenter make good use of the 10 minutes for presentation?  \n",
    "       0: the team didn't present\n",
    "       1: bad, barely finished a small part of the talk\n",
    "       2: okay, barely finished most parts of the talk.\n",
    "       3: good, finished all parts of the talk, but some part is rushed\n",
    "       4: very good, but the allocation of time on different parts can be improved.\n",
    "       5: perfect timing and good use of time      \n",
    "\n",
    "    12. How well do you think of the presentation (overall quality)?  \n",
    "       0: the team didn't present\n",
    "       1: bad\n",
    "       2: okay\n",
    "       3: good\n",
    "       4: very good\n",
    "       5: perfect\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Overall: \n",
    "    -----------------------------------\n",
    "    13. How many points out of the 100 do you give to this project in total?  Please don't worry about the absolute scores, we will rescale the final grading according to the performance of all teams in the class.\n",
    "    Total score:\n",
    "    \n",
    "    14. What are the strengths of this project? Briefly, list up to 3 strengths.\n",
    "       1: \n",
    "       2:\n",
    "       3:\n",
    "    \n",
    "    15. What are the weaknesses of this project? Briefly, list up to 3 weaknesses.\n",
    "       1:\n",
    "       2:\n",
    "       3:\n",
    "    \n",
    "    16. Detailed comments and suggestions. What suggestions do you have for this project to improve its quality further.\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ---------------------------------\n",
    "    Your Vote: \n",
    "    ---------------------------------\n",
    "    1. [Overall Quality] Between the two submissions that you are reviewing, which team would you vote for a better score?  \n",
    "       -1: I vote the other team is better than this team\n",
    "        0: the same\n",
    "        1: I vote this team is better than the other team \n",
    "        \n",
    "    2. [Presentation] Among all the teams in the presentation, which team do you think deserves the best presentation award for this case study?  \n",
    "        1: Team 1\n",
    "        2: Team 2\n",
    "        3: Team 3\n",
    "        4: Team 4\n",
    "        5: Team 5\n",
    "        6: Team 6\n",
    "        7: Team 7\n",
    "        8: Team 8\n",
    "        9: Team 9\n",
    "       10: Team 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
